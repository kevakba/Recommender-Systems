{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "tf_env",
      "language": "python",
      "name": "tf_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Recommender System — Matrix Factorization vs Neural Matrix Factorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfdea9cf"
      },
      "source": [
        "# importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import Dense, Lambda, Activation\n",
        "from keras.layers import Embedding, Input, Dense, merge, Reshape, Flatten, Dropout, Concatenate, Multiply #Merge\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from time import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "bfdea9cf",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "358d8dcc"
      },
      "source": [
        "# loading the dataframe\n",
        "df_main = pd.read_csv('sample30.csv')"
      ],
      "id": "358d8dcc",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91OIe9DAmYHL"
      },
      "source": [
        "### Data Cleaning:"
      ],
      "id": "91OIe9DAmYHL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66556e96"
      },
      "source": [
        "# filtering-in required columns\n",
        "df_reco = df_main[['name','reviews_username','reviews_rating']]"
      ],
      "id": "66556e96",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c9d73c4",
        "outputId": "14ae2bbc-4c4f-4dd1-b1e3-5e1c0a86cab9"
      },
      "source": [
        "# check for null values\n",
        "\n",
        "df_reco.isnull().sum()"
      ],
      "id": "7c9d73c4",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name                 0\n",
              "reviews_username    63\n",
              "reviews_rating       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33f8b6a6"
      },
      "source": [
        "# dropping rows with NaN values\n",
        "\n",
        "df_reco.dropna(axis=0, inplace=True)"
      ],
      "id": "33f8b6a6",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f68ab77",
        "outputId": "990e5fbe-eb8e-4417-d653-1b2a69d3f9f0"
      },
      "source": [
        "# check for duplicates\n",
        "\n",
        "df_reco.duplicated().sum()"
      ],
      "id": "2f68ab77",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2198"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17a01ec3"
      },
      "source": [
        "# dropping the duplicates\n",
        "\n",
        "df_reco.drop_duplicates(inplace=True)"
      ],
      "id": "17a01ec3",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39666bf8",
        "outputId": "ac81e519-a4d9-48b9-9b9c-3fbc655e70a1"
      },
      "source": [
        "# check for duplicates based on subset of 'name' and 'reviews_username'\n",
        "\n",
        "df_reco.duplicated(subset=['name','reviews_username']).sum()"
      ],
      "id": "39666bf8",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dce59a99"
      },
      "source": [
        "From above we note that we have certain users who have given two or more different ratings to the same products. Let us impute those ratings the average ratings."
      ],
      "id": "dce59a99"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "6bcc0be9",
        "outputId": "f918306f-bf5d-445c-9ff5-8382222aeb43"
      },
      "source": [
        "# get the average ratings for duplicated rows\n",
        "\n",
        "df_mean = df_reco[df_reco.duplicated(subset=['name','reviews_username'], keep=False)].groupby(\n",
        "    by=['name', 'reviews_username']).mean()\n",
        "\n",
        "df_mean"
      ],
      "id": "6bcc0be9",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>reviews_rating</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th>reviews_username</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100:Complete First Season (blu-Ray)</th>\n",
              "      <th>dontdodat</th>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alex Cross (dvdvideo)</th>\n",
              "      <th>mookie</th>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aveeno Baby Continuous Protection Lotion Sunscreen with Broad Spectrum SPF 55, 4oz</th>\n",
              "      <th>byamazon customer</th>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Avery174 Ready Index Contemporary Table Of Contents Divider, 1-8, Multi, Letter</th>\n",
              "      <th>gellis</th>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the office guro</th>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Tostitos Bite Size Tortilla Chips</th>\n",
              "      <th>debb</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rick</th>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sandy</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Windex Original Glass Cleaner Refill 67.6oz (2 Liter)</th>\n",
              "      <th>laura</th>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suri</th>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                      reviews_rating\n",
              "name                                               reviews_username                 \n",
              "100:Complete First Season (blu-Ray)                dontdodat                3.500000\n",
              "Alex Cross (dvdvideo)                              mookie                   4.500000\n",
              "Aveeno Baby Continuous Protection Lotion Sunscr... byamazon customer        2.666667\n",
              "Avery174 Ready Index Contemporary Table Of Cont... gellis                   4.500000\n",
              "                                                   the office guro          3.500000\n",
              "...                                                                              ...\n",
              "Tostitos Bite Size Tortilla Chips                  debb                     4.000000\n",
              "                                                   rick                     4.500000\n",
              "                                                   sandy                    3.000000\n",
              "Windex Original Glass Cleaner Refill 67.6oz (2 ... laura                    1.500000\n",
              "                                                   suri                     3.500000\n",
              "\n",
              "[135 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "c02e2833",
        "outputId": "cfe50a7c-7213-4fcd-c37e-7b3aa2bec4a3"
      },
      "source": [
        "# left merge the df_reco and df_mean dataframes over 'name' and 'reviews_username'\n",
        "\n",
        "df_merged = df_reco.merge(df_mean, how='left' , on=['name', 'reviews_username']).sort_values(\n",
        "    by=['name', 'reviews_username'])\n",
        "\n",
        "df_merged.head()"
      ],
      "id": "c02e2833",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>reviews_username</th>\n",
              "      <th>reviews_rating_x</th>\n",
              "      <th>reviews_rating_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19543</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>brewno</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19545</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>embum</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19547</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>granny</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19542</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>smokey bear</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19546</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>spicesea</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    name  ... reviews_rating_y\n",
              "19543  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...              NaN\n",
              "19545  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...              NaN\n",
              "19547  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...              NaN\n",
              "19542  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...              NaN\n",
              "19546  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...              NaN\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06136964",
        "outputId": "85c02c64-535f-4d7d-b74c-5260373f12cb"
      },
      "source": [
        "df_merged.isnull().sum()"
      ],
      "id": "06136964",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name                    0\n",
              "reviews_username        0\n",
              "reviews_rating_x        0\n",
              "reviews_rating_y    27453\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d052ab9a"
      },
      "source": [
        "Since we have very few such rows, we would have many NaN values in reviews_rating_y column. Let us concatenate the dataframe such that we get average values from reviews_rating_y column and normal ratings from reviews_rating_x column"
      ],
      "id": "d052ab9a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "552aaa62",
        "outputId": "e1d67b61-37dc-48f5-9ff7-131a9c968888"
      },
      "source": [
        "A = df_merged[df_merged['reviews_rating_y'].isnull()][['name','reviews_username','reviews_rating_x']]\n",
        "A.rename(columns={'reviews_rating_x':'reviews_rating_final'}, inplace=True)\n",
        "\n",
        "B = df_merged[df_merged['reviews_rating_y'].isnull()==False][['name','reviews_username','reviews_rating_y']]\n",
        "B.rename(columns={'reviews_rating_y':'reviews_rating_final'}, inplace=True)\n",
        "\n",
        "df_final= pd.concat([A, B])\n",
        "df_final.sort_values(by=['name', 'reviews_username'])"
      ],
      "id": "552aaa62",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>reviews_username</th>\n",
              "      <th>reviews_rating_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19543</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>brewno</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19545</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>embum</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19547</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>granny</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19542</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>smokey bear</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19546</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>spicesea</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20525</th>\n",
              "      <td>Yes To Grapefruit Rejuvenating Body Wash</td>\n",
              "      <td>sheila</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20534</th>\n",
              "      <td>Yes To Grapefruit Rejuvenating Body Wash</td>\n",
              "      <td>skeel</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20531</th>\n",
              "      <td>Yes To Grapefruit Rejuvenating Body Wash</td>\n",
              "      <td>td33</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20553</th>\n",
              "      <td>Yes To Grapefruit Rejuvenating Body Wash</td>\n",
              "      <td>trishaxo2u</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20544</th>\n",
              "      <td>Yes To Grapefruit Rejuvenating Body Wash</td>\n",
              "      <td>yogagirl</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27739 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    name  ... reviews_rating_final\n",
              "19543  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  3.0\n",
              "19545  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  5.0\n",
              "19547  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  5.0\n",
              "19542  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  3.0\n",
              "19546  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  5.0\n",
              "...                                                  ...  ...                  ...\n",
              "20525           Yes To Grapefruit Rejuvenating Body Wash  ...                  1.0\n",
              "20534           Yes To Grapefruit Rejuvenating Body Wash  ...                  4.0\n",
              "20531           Yes To Grapefruit Rejuvenating Body Wash  ...                  3.0\n",
              "20553           Yes To Grapefruit Rejuvenating Body Wash  ...                  5.0\n",
              "20544           Yes To Grapefruit Rejuvenating Body Wash  ...                  5.0\n",
              "\n",
              "[27739 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4263c3ce",
        "outputId": "6064f0db-48e0-4f82-c5d6-788040ca4055"
      },
      "source": [
        "# check for duplicates from `df_final` df\n",
        "df_final.duplicated().sum()"
      ],
      "id": "4263c3ce",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86d1bc35"
      },
      "source": [
        "# drop duplicates from 'df_final' df\n",
        "\n",
        "df_final.drop_duplicates(inplace=True)"
      ],
      "id": "86d1bc35",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "15877d17",
        "outputId": "652e0dd2-058d-49e5-e4a9-bac2bf91367a"
      },
      "source": [
        "df_final.head()"
      ],
      "id": "15877d17",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>reviews_username</th>\n",
              "      <th>reviews_rating_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19543</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>brewno</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19545</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>embum</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19547</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>granny</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19542</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>smokey bear</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19546</th>\n",
              "      <td>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...</td>\n",
              "      <td>spicesea</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    name  ... reviews_rating_final\n",
              "19543  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  3.0\n",
              "19545  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  5.0\n",
              "19547  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  5.0\n",
              "19542  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  3.0\n",
              "19546  0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. ...  ...                  5.0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "79ed4d75",
        "outputId": "cb535d25-485e-43f7-b849-87df5a2ae456"
      },
      "source": [
        "df_final['reviews_rating_final'].value_counts().plot.bar()\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('No. of ratings')\n",
        "plt.show()"
      ],
      "id": "79ed4d75",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIcBhkEPcBZt",
        "outputId": "7c38a98d-353d-47c9-d598-c796648e2996"
      },
      "source": [
        "df_final.duplicated().sum()"
      ],
      "id": "EIcBhkEPcBZt",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MOMBEUdmxOH"
      },
      "source": [
        "### Data Preparation:"
      ],
      "id": "9MOMBEUdmxOH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJx6RYZzMeHN",
        "outputId": "0589a3ae-354a-4a16-df4f-923133deb160"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Train, Test = train_test_split(df_final, test_size=0.2, random_state=32)\n",
        "\n",
        "print(Train.shape)\n",
        "print(Test.shape)"
      ],
      "id": "SJx6RYZzMeHN",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22070, 3)\n",
            "(5518, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SpD1EtIm8n_"
      },
      "source": [
        "We would only be able to test those users and items which are already in our database (Train set). So let's filter-in such common entries and prepare our Test set. "
      ],
      "id": "3SpD1EtIm8n_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE6msdWSM2G0",
        "outputId": "2c2808a0-c9d8-4571-c068-6f1dac083f40"
      },
      "source": [
        "Test = Test[(Test.name.isin(Train.name)) & (Test.reviews_username.isin(Train.reviews_username))]\n",
        "print(Test.shape)"
      ],
      "id": "GE6msdWSM2G0",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(779, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27c1fa9f"
      },
      "source": [
        "### Matrix Factorization Method:"
      ],
      "id": "27c1fa9f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b275307c"
      },
      "source": [
        "# Create a user-product matrix.\n",
        "df_pivot = Train.pivot(\n",
        "    index='reviews_username',\n",
        "    columns='name',\n",
        "    values='reviews_rating_final'\n",
        ").fillna(0)\n",
        "\n",
        "\n",
        "R = np.array(df_pivot)\n",
        "# N: num of User\n",
        "N = R.shape[0]\n",
        "# M: num of Movie\n",
        "M = R.shape[1]\n",
        "# K: latent features\n",
        "K = 50\n",
        "\n",
        "P = np.random.rand(N,K)\n",
        "Q = np.random.rand(M,K)\n"
      ],
      "id": "b275307c",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fedf8f4"
      },
      "source": [
        "def matrix_factorization(R, P, Q, K, steps=50, alpha=0.0002, beta=0.02):\n",
        "    '''\n",
        "    R: rating matrix\n",
        "    P: |U| * K (User features matrix)\n",
        "    Q: |D| * K (Item features matrix)\n",
        "    K: latent features\n",
        "    steps: iterations\n",
        "    alpha: learning rate\n",
        "    beta: regularization parameter'''\n",
        "    \n",
        "    Q = Q.T\n",
        "\n",
        "    for step in range(steps):\n",
        "        for i in range(len(R)):\n",
        "            for j in range(len(R[i])):\n",
        "                if R[i][j] > 0:\n",
        "                    # calculate error\n",
        "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
        "\n",
        "                    for k in range(K):\n",
        "                        # calculate gradient with a and beta parameter\n",
        "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
        "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
        "\n",
        "        eR = np.dot(P,Q)\n",
        "\n",
        "        e = 0\n",
        "\n",
        "        for i in range(len(R)):\n",
        "            for j in range(len(R[i])):\n",
        "                if R[i][j] > 0:\n",
        "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
        "                    for k in range(K):\n",
        "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))    # addting L2 regularisation error in the total error\n",
        "        \n",
        "        if e < 0.001: # 0.001: local minimum\n",
        "            break\n",
        "\n",
        "    return P, Q.T"
      ],
      "id": "7fedf8f4",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0e5e29f"
      },
      "source": [
        "nP, nQ = matrix_factorization(R, P, Q, K)\n",
        "nR = np.dot(nP, nQ.T)"
      ],
      "id": "d0e5e29f",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "b4f59572",
        "outputId": "ecef898f-b8bf-48c0-9b23-3751a9336279"
      },
      "source": [
        "# checking predicted ratings with MF method\n",
        "pred_R = pd.DataFrame(nR, columns = df_pivot.columns, index = df_pivot.index)\n",
        "pred_R.head()"
      ],
      "id": "b4f59572",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>name</th>\n",
              "      <th>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. Fire File Chest</th>\n",
              "      <th>100:Complete First Season (blu-Ray)</th>\n",
              "      <th>2017-2018 Brownline174 Duraflex 14-Month Planner 8 1/2 X 11 Black</th>\n",
              "      <th>2x Ultra Era with Oxi Booster, 50fl oz</th>\n",
              "      <th>4C Grated Parmesan Cheese 100% Natural 8oz Shaker</th>\n",
              "      <th>Africa's Best No-Lye Dual Conditioning Relaxer System Super</th>\n",
              "      <th>Alberto VO5 Salon Series Smooth Plus Sleek Shampoo</th>\n",
              "      <th>Alex Cross (dvdvideo)</th>\n",
              "      <th>All,bran Complete Wheat Flakes, 18 Oz.</th>\n",
              "      <th>Ambi Complexion Cleansing Bar</th>\n",
              "      <th>Annie's Homegrown Deluxe Elbows &amp; Four Cheese Sauce</th>\n",
              "      <th>Annie's Homegrown Gluten Free Double Chocolate Chip Granola Bars</th>\n",
              "      <th>Arrid Extra Dry Anti-Perspirant Deodorant Spray Regular</th>\n",
              "      <th>Aussie Aussome Volume Shampoo, 13.5 Oz</th>\n",
              "      <th>Australian Gold Exotic Blend Lotion, SPF 4</th>\n",
              "      <th>Aveeno Baby Continuous Protection Lotion Sunscreen with Broad Spectrum SPF 55, 4oz</th>\n",
              "      <th>Avery174 11-1/4 X 9-1/4 Index Maker Extra Wide Label Dividers With 5 Tab - Clear (5 Sets Per Pack)</th>\n",
              "      <th>Avery174 Ready Index Contemporary Table Of Contents Divider, 1-8, Multi, Letter</th>\n",
              "      <th>Axe Dry Anti-Perspirant Deodorant Invisible Solid Phoenix</th>\n",
              "      <th>BRIDGESTONE 130/70ZR18M/C(63W)FRONT EXEDRA G851, CRUISER RADL</th>\n",
              "      <th>Banana Boat Sunless Summer Color Self Tanning Lotion, Light To Medium</th>\n",
              "      <th>Barielle Nail Rebuilding Protein</th>\n",
              "      <th>Batherapy Natural Mineral Bath Sport Liquid, 16 oz</th>\n",
              "      <th>Baxter Of California Cream Pomade</th>\n",
              "      <th>Beanitos Bean Chips, Simply Pinto Bean</th>\n",
              "      <th>Bedtime Originals Pinkie Musical Mobile</th>\n",
              "      <th>Ben &amp; Jerry's Coffee, Coffee Buzzbuzzbuzz! Ice Cream, Pint</th>\n",
              "      <th>Better Built 74010862 Bet74010862 60In Crossover Two Lid, Deep, Truck Tool Box</th>\n",
              "      <th>Bi-O-kleen Spray &amp; Wipe All Purpose Cleaner</th>\n",
              "      <th>Bilbao Nightstand Gray Oak - South Shore</th>\n",
              "      <th>Bill Glor Gaither - Church In The Wildwood (cd)</th>\n",
              "      <th>Bisquick Original Pancake And Baking Mix - 40oz</th>\n",
              "      <th>Black Front Loading Frame Set (8.5x11) Set Of 12</th>\n",
              "      <th>Black Sister's Revenge (dvd)</th>\n",
              "      <th>Bodycology Nourishing Body Cream, Pretty In Paris</th>\n",
              "      <th>Boraam Sonoma Kitchen Cart With Wire Brush Gray - Maaya Home</th>\n",
              "      <th>Bounce Dryer Sheets, Fresh Linen, 160 sheets</th>\n",
              "      <th>Bumble Bee Solid White Albacore In Water - 5 Oz</th>\n",
              "      <th>Burt's Bees Lip Shimmer, Raisin</th>\n",
              "      <th>Burt's Bees Lip Shimmer, Watermelon</th>\n",
              "      <th>...</th>\n",
              "      <th>Starbucks153 Doubleshot Protein Coffee - 11 Fl Oz</th>\n",
              "      <th>Stargate (ws) (ultimate Edition) (director's Cut) (dvdvideo)</th>\n",
              "      <th>Stonyfield Yobaby Peach &amp; Pear Yogurt 4oz 6 Ct</th>\n",
              "      <th>Storkcraft Tuscany Glider and Ottoman, Beige Cushions, Espresso Finish</th>\n",
              "      <th>Suave Professionals Hair Conditioner, Sleek</th>\n",
              "      <th>Sunflower Swag With Metal Frame - Nearly Natural</th>\n",
              "      <th>Super Poligrip Denture Adhesive Cream, Ultra Fresh - 2.4 Oz</th>\n",
              "      <th>Switchmas (dvd)</th>\n",
              "      <th>Tai Pei Sweet &amp; Sour Chicken</th>\n",
              "      <th>The Honest Company Laundry Detergent</th>\n",
              "      <th>The Resident Evil Collection 5 Discs (blu-Ray)</th>\n",
              "      <th>The Script - No Sound Without Silence (cd)</th>\n",
              "      <th>The Seaweed Bath Co. Argan Conditioner, Smoothing Citrus</th>\n",
              "      <th>There's Something About Mary (dvd)</th>\n",
              "      <th>Tim Holtz Retractable Craft Pick-Red 6x.5</th>\n",
              "      <th>Tostitos Bite Size Tortilla Chips</th>\n",
              "      <th>Tostitos Simply Blue Corn Tortilla Chips</th>\n",
              "      <th>Toy Story Kids' Woody Accessory Kit</th>\n",
              "      <th>Tramontina Ceramica 10 Piece Cookware Set - Red</th>\n",
              "      <th>Tree Hut Shea Body Butters, Coconut Lime, 7 oz</th>\n",
              "      <th>Trend Lab Park Nursing Cover - Paisley</th>\n",
              "      <th>Tresemme Kertatin Smooth Infusing Conditioning</th>\n",
              "      <th>Udi's Pepperoni Pizza</th>\n",
              "      <th>Various - Country's Greatest Gospel:Gold Ed (cd)</th>\n",
              "      <th>Various - Red Hot Blue:Tribute To Cole Porter (cd)</th>\n",
              "      <th>Various Artists - Choo Choo Soul (cd)</th>\n",
              "      <th>Vaseline Intensive Care Healthy Hands Stronger Nails</th>\n",
              "      <th>Vaseline Intensive Care Lip Therapy Cocoa Butter</th>\n",
              "      <th>Vicks Vaporub, Regular, 3.53oz</th>\n",
              "      <th>Voortman Sugar Free Fudge Chocolate Chip Cookies</th>\n",
              "      <th>Wagan Smartac 80watt Inverter With Usb</th>\n",
              "      <th>Walkers Stem Ginger Shortbread</th>\n",
              "      <th>Way Basics 3-Shelf Eco Narrow Bookcase Storage Shelf, Espresso - Formaldehyde Free - Lifetime Guarantee</th>\n",
              "      <th>WeatherTech 40647 14-15 Outlander Cargo Liners Behind 2nd Row, Black</th>\n",
              "      <th>Wedding Wishes Wedding Guest Book</th>\n",
              "      <th>Weleda Everon Lip Balm</th>\n",
              "      <th>Wilton Black Dots Standard Baking Cups</th>\n",
              "      <th>Windex Original Glass Cleaner Refill 67.6oz (2 Liter)</th>\n",
              "      <th>Yes To Carrots Nourishing Body Wash</th>\n",
              "      <th>Yes To Grapefruit Rejuvenating Body Wash</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_username</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00dog3</th>\n",
              "      <td>8.023277</td>\n",
              "      <td>4.580599</td>\n",
              "      <td>7.541164</td>\n",
              "      <td>9.074351</td>\n",
              "      <td>8.455410</td>\n",
              "      <td>7.005395</td>\n",
              "      <td>7.163304</td>\n",
              "      <td>4.010732</td>\n",
              "      <td>6.116511</td>\n",
              "      <td>8.370047</td>\n",
              "      <td>8.386041</td>\n",
              "      <td>6.066180</td>\n",
              "      <td>3.727548</td>\n",
              "      <td>4.381098</td>\n",
              "      <td>5.286328</td>\n",
              "      <td>3.112575</td>\n",
              "      <td>9.499044</td>\n",
              "      <td>3.895591</td>\n",
              "      <td>4.684585</td>\n",
              "      <td>5.425500</td>\n",
              "      <td>3.729390</td>\n",
              "      <td>6.404496</td>\n",
              "      <td>8.902675</td>\n",
              "      <td>6.724565</td>\n",
              "      <td>10.087147</td>\n",
              "      <td>6.224843</td>\n",
              "      <td>5.197011</td>\n",
              "      <td>6.181811</td>\n",
              "      <td>5.726609</td>\n",
              "      <td>5.492619</td>\n",
              "      <td>8.864600</td>\n",
              "      <td>4.425605</td>\n",
              "      <td>4.473236</td>\n",
              "      <td>11.369978</td>\n",
              "      <td>11.187650</td>\n",
              "      <td>4.176324</td>\n",
              "      <td>4.820957</td>\n",
              "      <td>6.029903</td>\n",
              "      <td>4.468381</td>\n",
              "      <td>4.657923</td>\n",
              "      <td>...</td>\n",
              "      <td>8.472595</td>\n",
              "      <td>3.925973</td>\n",
              "      <td>10.054603</td>\n",
              "      <td>3.710230</td>\n",
              "      <td>3.204406</td>\n",
              "      <td>8.502253</td>\n",
              "      <td>4.453632</td>\n",
              "      <td>6.338443</td>\n",
              "      <td>3.717500</td>\n",
              "      <td>3.153537</td>\n",
              "      <td>3.928777</td>\n",
              "      <td>3.508007</td>\n",
              "      <td>5.432500</td>\n",
              "      <td>4.740248</td>\n",
              "      <td>8.765126</td>\n",
              "      <td>4.845220</td>\n",
              "      <td>5.024573</td>\n",
              "      <td>6.026784</td>\n",
              "      <td>8.660594</td>\n",
              "      <td>4.948561</td>\n",
              "      <td>4.823781</td>\n",
              "      <td>3.583143</td>\n",
              "      <td>10.010991</td>\n",
              "      <td>8.247040</td>\n",
              "      <td>8.305377</td>\n",
              "      <td>5.119788</td>\n",
              "      <td>3.406665</td>\n",
              "      <td>3.953303</td>\n",
              "      <td>4.226949</td>\n",
              "      <td>7.607168</td>\n",
              "      <td>7.349243</td>\n",
              "      <td>10.556645</td>\n",
              "      <td>4.819321</td>\n",
              "      <td>5.006439</td>\n",
              "      <td>11.733196</td>\n",
              "      <td>5.464899</td>\n",
              "      <td>10.163837</td>\n",
              "      <td>4.335542</td>\n",
              "      <td>3.856850</td>\n",
              "      <td>4.055966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00sab00</th>\n",
              "      <td>8.778427</td>\n",
              "      <td>4.773697</td>\n",
              "      <td>7.558172</td>\n",
              "      <td>9.524271</td>\n",
              "      <td>9.023355</td>\n",
              "      <td>8.840535</td>\n",
              "      <td>9.328040</td>\n",
              "      <td>4.374786</td>\n",
              "      <td>8.079900</td>\n",
              "      <td>9.392437</td>\n",
              "      <td>10.689938</td>\n",
              "      <td>6.077471</td>\n",
              "      <td>5.248249</td>\n",
              "      <td>4.349622</td>\n",
              "      <td>5.432041</td>\n",
              "      <td>2.964142</td>\n",
              "      <td>12.101480</td>\n",
              "      <td>5.519170</td>\n",
              "      <td>4.172849</td>\n",
              "      <td>6.376882</td>\n",
              "      <td>4.431311</td>\n",
              "      <td>7.192780</td>\n",
              "      <td>10.017922</td>\n",
              "      <td>8.030132</td>\n",
              "      <td>12.020845</td>\n",
              "      <td>7.540584</td>\n",
              "      <td>6.827883</td>\n",
              "      <td>6.423239</td>\n",
              "      <td>6.128434</td>\n",
              "      <td>7.291823</td>\n",
              "      <td>10.949646</td>\n",
              "      <td>3.806994</td>\n",
              "      <td>7.650025</td>\n",
              "      <td>13.255794</td>\n",
              "      <td>14.061320</td>\n",
              "      <td>3.958850</td>\n",
              "      <td>5.152173</td>\n",
              "      <td>6.269972</td>\n",
              "      <td>4.673101</td>\n",
              "      <td>5.610284</td>\n",
              "      <td>...</td>\n",
              "      <td>11.124807</td>\n",
              "      <td>5.512408</td>\n",
              "      <td>11.931265</td>\n",
              "      <td>5.016941</td>\n",
              "      <td>4.679227</td>\n",
              "      <td>10.241899</td>\n",
              "      <td>5.860096</td>\n",
              "      <td>7.443387</td>\n",
              "      <td>3.884530</td>\n",
              "      <td>4.950481</td>\n",
              "      <td>4.923741</td>\n",
              "      <td>4.517750</td>\n",
              "      <td>6.425919</td>\n",
              "      <td>4.968445</td>\n",
              "      <td>10.512022</td>\n",
              "      <td>5.171280</td>\n",
              "      <td>5.126176</td>\n",
              "      <td>6.637240</td>\n",
              "      <td>9.928240</td>\n",
              "      <td>4.550063</td>\n",
              "      <td>5.313990</td>\n",
              "      <td>3.578887</td>\n",
              "      <td>13.047036</td>\n",
              "      <td>9.822646</td>\n",
              "      <td>9.427055</td>\n",
              "      <td>5.436653</td>\n",
              "      <td>4.901778</td>\n",
              "      <td>4.687733</td>\n",
              "      <td>5.238064</td>\n",
              "      <td>9.508133</td>\n",
              "      <td>8.904975</td>\n",
              "      <td>11.518709</td>\n",
              "      <td>5.527485</td>\n",
              "      <td>6.917123</td>\n",
              "      <td>13.030624</td>\n",
              "      <td>6.924219</td>\n",
              "      <td>11.823686</td>\n",
              "      <td>4.202736</td>\n",
              "      <td>5.292694</td>\n",
              "      <td>3.963343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01impala</th>\n",
              "      <td>6.800969</td>\n",
              "      <td>3.878086</td>\n",
              "      <td>6.549700</td>\n",
              "      <td>7.436644</td>\n",
              "      <td>8.626506</td>\n",
              "      <td>7.167561</td>\n",
              "      <td>7.798857</td>\n",
              "      <td>3.862947</td>\n",
              "      <td>4.926051</td>\n",
              "      <td>8.331304</td>\n",
              "      <td>8.972129</td>\n",
              "      <td>5.497350</td>\n",
              "      <td>3.136066</td>\n",
              "      <td>3.339044</td>\n",
              "      <td>5.534212</td>\n",
              "      <td>2.576700</td>\n",
              "      <td>10.152742</td>\n",
              "      <td>3.988492</td>\n",
              "      <td>4.070628</td>\n",
              "      <td>5.882077</td>\n",
              "      <td>3.461141</td>\n",
              "      <td>5.832112</td>\n",
              "      <td>8.288063</td>\n",
              "      <td>6.537864</td>\n",
              "      <td>9.902970</td>\n",
              "      <td>6.377889</td>\n",
              "      <td>5.899041</td>\n",
              "      <td>6.258807</td>\n",
              "      <td>4.771853</td>\n",
              "      <td>6.107961</td>\n",
              "      <td>9.591197</td>\n",
              "      <td>3.769283</td>\n",
              "      <td>5.495805</td>\n",
              "      <td>11.839744</td>\n",
              "      <td>12.399889</td>\n",
              "      <td>4.701671</td>\n",
              "      <td>4.386080</td>\n",
              "      <td>5.856806</td>\n",
              "      <td>4.157171</td>\n",
              "      <td>4.445918</td>\n",
              "      <td>...</td>\n",
              "      <td>9.202224</td>\n",
              "      <td>3.892699</td>\n",
              "      <td>10.318866</td>\n",
              "      <td>4.347908</td>\n",
              "      <td>3.358369</td>\n",
              "      <td>8.419499</td>\n",
              "      <td>4.788056</td>\n",
              "      <td>4.903669</td>\n",
              "      <td>2.999447</td>\n",
              "      <td>3.365451</td>\n",
              "      <td>3.755192</td>\n",
              "      <td>4.424612</td>\n",
              "      <td>5.800592</td>\n",
              "      <td>4.344957</td>\n",
              "      <td>9.233367</td>\n",
              "      <td>5.636712</td>\n",
              "      <td>4.888387</td>\n",
              "      <td>6.141112</td>\n",
              "      <td>8.257356</td>\n",
              "      <td>3.408441</td>\n",
              "      <td>5.590154</td>\n",
              "      <td>3.701821</td>\n",
              "      <td>10.545154</td>\n",
              "      <td>7.900282</td>\n",
              "      <td>7.322545</td>\n",
              "      <td>4.955243</td>\n",
              "      <td>4.859857</td>\n",
              "      <td>3.794615</td>\n",
              "      <td>4.398565</td>\n",
              "      <td>7.045288</td>\n",
              "      <td>7.552130</td>\n",
              "      <td>9.949578</td>\n",
              "      <td>4.756383</td>\n",
              "      <td>4.967981</td>\n",
              "      <td>12.169545</td>\n",
              "      <td>6.393492</td>\n",
              "      <td>10.696150</td>\n",
              "      <td>3.709503</td>\n",
              "      <td>4.087006</td>\n",
              "      <td>3.405479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02dakota</th>\n",
              "      <td>8.550351</td>\n",
              "      <td>4.282033</td>\n",
              "      <td>7.505166</td>\n",
              "      <td>8.949411</td>\n",
              "      <td>8.172061</td>\n",
              "      <td>7.746648</td>\n",
              "      <td>9.923995</td>\n",
              "      <td>4.252593</td>\n",
              "      <td>6.052499</td>\n",
              "      <td>8.868179</td>\n",
              "      <td>10.557992</td>\n",
              "      <td>6.600204</td>\n",
              "      <td>4.804774</td>\n",
              "      <td>4.382404</td>\n",
              "      <td>5.154210</td>\n",
              "      <td>3.656311</td>\n",
              "      <td>12.316744</td>\n",
              "      <td>5.632014</td>\n",
              "      <td>4.291196</td>\n",
              "      <td>7.091056</td>\n",
              "      <td>3.968535</td>\n",
              "      <td>7.824691</td>\n",
              "      <td>10.032493</td>\n",
              "      <td>8.185624</td>\n",
              "      <td>11.340058</td>\n",
              "      <td>8.726183</td>\n",
              "      <td>6.979154</td>\n",
              "      <td>6.476958</td>\n",
              "      <td>4.715117</td>\n",
              "      <td>5.748034</td>\n",
              "      <td>11.297647</td>\n",
              "      <td>5.328515</td>\n",
              "      <td>5.096925</td>\n",
              "      <td>13.618482</td>\n",
              "      <td>14.506659</td>\n",
              "      <td>4.996004</td>\n",
              "      <td>4.619788</td>\n",
              "      <td>5.893704</td>\n",
              "      <td>4.442815</td>\n",
              "      <td>6.514908</td>\n",
              "      <td>...</td>\n",
              "      <td>8.596473</td>\n",
              "      <td>4.142208</td>\n",
              "      <td>11.416917</td>\n",
              "      <td>5.085823</td>\n",
              "      <td>3.931673</td>\n",
              "      <td>10.104475</td>\n",
              "      <td>4.924509</td>\n",
              "      <td>6.659608</td>\n",
              "      <td>4.116301</td>\n",
              "      <td>5.429650</td>\n",
              "      <td>4.698530</td>\n",
              "      <td>4.378077</td>\n",
              "      <td>6.847305</td>\n",
              "      <td>5.463666</td>\n",
              "      <td>9.379077</td>\n",
              "      <td>4.862010</td>\n",
              "      <td>5.153614</td>\n",
              "      <td>7.875516</td>\n",
              "      <td>9.842288</td>\n",
              "      <td>4.254085</td>\n",
              "      <td>6.255458</td>\n",
              "      <td>4.652730</td>\n",
              "      <td>11.318940</td>\n",
              "      <td>9.614268</td>\n",
              "      <td>8.141118</td>\n",
              "      <td>5.570760</td>\n",
              "      <td>3.952183</td>\n",
              "      <td>4.278886</td>\n",
              "      <td>4.613673</td>\n",
              "      <td>8.803283</td>\n",
              "      <td>7.932847</td>\n",
              "      <td>11.567435</td>\n",
              "      <td>6.147498</td>\n",
              "      <td>7.351436</td>\n",
              "      <td>14.330057</td>\n",
              "      <td>6.312194</td>\n",
              "      <td>10.467277</td>\n",
              "      <td>3.627650</td>\n",
              "      <td>3.691436</td>\n",
              "      <td>4.026283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>02deuce</th>\n",
              "      <td>6.887242</td>\n",
              "      <td>3.930566</td>\n",
              "      <td>7.582062</td>\n",
              "      <td>8.724999</td>\n",
              "      <td>7.747464</td>\n",
              "      <td>7.834557</td>\n",
              "      <td>8.159322</td>\n",
              "      <td>3.980907</td>\n",
              "      <td>5.151041</td>\n",
              "      <td>8.203124</td>\n",
              "      <td>10.041609</td>\n",
              "      <td>5.855309</td>\n",
              "      <td>3.788216</td>\n",
              "      <td>3.936241</td>\n",
              "      <td>5.839033</td>\n",
              "      <td>3.408130</td>\n",
              "      <td>9.236918</td>\n",
              "      <td>3.950590</td>\n",
              "      <td>4.913300</td>\n",
              "      <td>5.729588</td>\n",
              "      <td>3.851626</td>\n",
              "      <td>5.733310</td>\n",
              "      <td>7.552708</td>\n",
              "      <td>7.154882</td>\n",
              "      <td>10.808470</td>\n",
              "      <td>7.758239</td>\n",
              "      <td>6.492506</td>\n",
              "      <td>6.276503</td>\n",
              "      <td>4.331835</td>\n",
              "      <td>5.126849</td>\n",
              "      <td>10.595557</td>\n",
              "      <td>4.925588</td>\n",
              "      <td>5.262755</td>\n",
              "      <td>10.855399</td>\n",
              "      <td>11.753307</td>\n",
              "      <td>4.752366</td>\n",
              "      <td>4.817987</td>\n",
              "      <td>5.574864</td>\n",
              "      <td>4.507710</td>\n",
              "      <td>5.320934</td>\n",
              "      <td>...</td>\n",
              "      <td>8.845773</td>\n",
              "      <td>4.134762</td>\n",
              "      <td>9.897365</td>\n",
              "      <td>3.412224</td>\n",
              "      <td>3.614373</td>\n",
              "      <td>9.012600</td>\n",
              "      <td>5.243781</td>\n",
              "      <td>6.314470</td>\n",
              "      <td>3.125541</td>\n",
              "      <td>4.530310</td>\n",
              "      <td>4.168654</td>\n",
              "      <td>3.423502</td>\n",
              "      <td>7.224047</td>\n",
              "      <td>4.479589</td>\n",
              "      <td>10.070836</td>\n",
              "      <td>4.820515</td>\n",
              "      <td>4.810473</td>\n",
              "      <td>5.968003</td>\n",
              "      <td>9.438009</td>\n",
              "      <td>3.645982</td>\n",
              "      <td>6.155191</td>\n",
              "      <td>4.216819</td>\n",
              "      <td>11.815257</td>\n",
              "      <td>7.824756</td>\n",
              "      <td>6.705588</td>\n",
              "      <td>3.853577</td>\n",
              "      <td>4.623759</td>\n",
              "      <td>4.664473</td>\n",
              "      <td>3.935534</td>\n",
              "      <td>7.897656</td>\n",
              "      <td>8.085839</td>\n",
              "      <td>10.330833</td>\n",
              "      <td>5.432451</td>\n",
              "      <td>5.479636</td>\n",
              "      <td>11.902983</td>\n",
              "      <td>6.828450</td>\n",
              "      <td>9.817528</td>\n",
              "      <td>3.787042</td>\n",
              "      <td>3.576898</td>\n",
              "      <td>4.250278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "name              0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. Fire File Chest  ...  Yes To Grapefruit Rejuvenating Body Wash\n",
              "reviews_username                                                                 ...                                          \n",
              "00dog3                                                     8.023277              ...                                  4.055966\n",
              "00sab00                                                    8.778427              ...                                  3.963343\n",
              "01impala                                                   6.800969              ...                                  3.405479\n",
              "02dakota                                                   8.550351              ...                                  4.026283\n",
              "02deuce                                                    6.887242              ...                                  4.250278\n",
              "\n",
              "[5 rows x 258 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1jdpFWSnQg3"
      },
      "source": [
        "#### MF Model evaluation:"
      ],
      "id": "z1jdpFWSnQg3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "aPzn9mjtVV2b",
        "outputId": "6dce4e48-ea25-4b42-c8cd-05d5d3958e9e"
      },
      "source": [
        "df_test = Test.pivot(\n",
        "    index='reviews_username',\n",
        "    columns='name',\n",
        "    values='reviews_rating_final'\n",
        ").fillna(0)\n",
        "\n",
        "df_test.head()"
      ],
      "id": "aPzn9mjtVV2b",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>name</th>\n",
              "      <th>0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. Fire File Chest</th>\n",
              "      <th>100:Complete First Season (blu-Ray)</th>\n",
              "      <th>Alex Cross (dvdvideo)</th>\n",
              "      <th>All,bran Complete Wheat Flakes, 18 Oz.</th>\n",
              "      <th>Aussie Aussome Volume Shampoo, 13.5 Oz</th>\n",
              "      <th>Australian Gold Exotic Blend Lotion, SPF 4</th>\n",
              "      <th>Aveeno Baby Continuous Protection Lotion Sunscreen with Broad Spectrum SPF 55, 4oz</th>\n",
              "      <th>Avery174 Ready Index Contemporary Table Of Contents Divider, 1-8, Multi, Letter</th>\n",
              "      <th>BRIDGESTONE 130/70ZR18M/C(63W)FRONT EXEDRA G851, CRUISER RADL</th>\n",
              "      <th>Beanitos Bean Chips, Simply Pinto Bean</th>\n",
              "      <th>Ben &amp; Jerry's Coffee, Coffee Buzzbuzzbuzz! Ice Cream, Pint</th>\n",
              "      <th>Bisquick Original Pancake And Baking Mix - 40oz</th>\n",
              "      <th>Boraam Sonoma Kitchen Cart With Wire Brush Gray - Maaya Home</th>\n",
              "      <th>Bounce Dryer Sheets, Fresh Linen, 160 sheets</th>\n",
              "      <th>Burt's Bees Lip Shimmer, Raisin</th>\n",
              "      <th>Caress Moisturizing Body Bar Natural Silk, 4.75oz</th>\n",
              "      <th>CeraVe SA Renewing Cream</th>\n",
              "      <th>Cheetos Crunchy Flamin' Hot Cheese Flavored Snacks</th>\n",
              "      <th>Chester's Cheese Flavored Puffcorn Snacks</th>\n",
              "      <th>Chex Muddy Buddies Brownie Supreme Snack Mix</th>\n",
              "      <th>Chips Ahoy! Original Chocolate Chip - Cookies - Family Size 18.2oz</th>\n",
              "      <th>Chobani174 Strawberry On The Bottom Non-Fat Greek Yogurt - 5.3oz</th>\n",
              "      <th>Clear Scalp &amp; Hair Therapy Total Care Nourishing Shampoo</th>\n",
              "      <th>Clorox Disinfecting Bathroom Cleaner</th>\n",
              "      <th>Clorox Disinfecting Wipes Value Pack Scented 150 Ct Total</th>\n",
              "      <th>Coty Airspun Face Powder, Translucent Extra Coverage</th>\n",
              "      <th>D-Con Mice Bait Station - 3ct</th>\n",
              "      <th>Dark Shadows (includes Digital Copy) (ultraviolet) (dvdvideo)</th>\n",
              "      <th>Equals (blu-Ray)</th>\n",
              "      <th>Feit 60-Watt A19 Gu24 Base Led Light Bulb - Soft White</th>\n",
              "      <th>Finish Quantum Dishwasher Detergent, Lemon Sparkle Scent, 45 Count</th>\n",
              "      <th>Fiskars174 Classic Stick Rotary Cutter (45 Mm)</th>\n",
              "      <th>Godzilla 3d Includes Digital Copy Ultraviolet 3d/2d Blu-Ray/dvd</th>\n",
              "      <th>Happy Tot Apple and Butternut Squash</th>\n",
              "      <th>Head &amp; Shoulders Classic Clean Conditioner</th>\n",
              "      <th>Head &amp; Shoulders Dandruff Shampoo Ocean Lift 2 In 1</th>\n",
              "      <th>Hollywood Beauty Olive Cholesterol</th>\n",
              "      <th>Home Health Hairever Shampoo</th>\n",
              "      <th>Hoover174 Platinum Collection153 Lightweight Bagged Upright Vacuum With Canister - Uh30010com</th>\n",
              "      <th>Hormel Chili, No Beans</th>\n",
              "      <th>...</th>\n",
              "      <th>Newman's Own Organics Licorice Twist, Black 5oz</th>\n",
              "      <th>Nexxus Exxtra Gel Style Creation Sculptor</th>\n",
              "      <th>Ogx Conditioner, Hydrating Teatree Mint</th>\n",
              "      <th>Olay Regenerist Deep Hydration Regenerating Cream</th>\n",
              "      <th>Pendaflex174 Divide It Up File Folder, Multi Section, Letter, Assorted, 12/pack</th>\n",
              "      <th>Physicians Formula Powder Palette Mineral Glow Pearls, Translucent Pearl</th>\n",
              "      <th>Planes: Fire Rescue (2 Discs) (includes Digital Copy) (blu-Ray/dvd)</th>\n",
              "      <th>Pleasant Hearth 1,800 sq ft Wood Burning Stove with Blower, Medium, LWS-127201</th>\n",
              "      <th>Pleasant Hearth Diamond Fireplace Screen - Espresso</th>\n",
              "      <th>Power Crunch Protein Energy Bar Peanut Butter Creme Original</th>\n",
              "      <th>Progresso Traditional Chicken Tuscany Soup</th>\n",
              "      <th>Queen Helene Cocoa Butter Solid</th>\n",
              "      <th>Ragu Roasted Garlic Parmesan Pasta Sauce</th>\n",
              "      <th>Ragu Traditional Pasta Sauce</th>\n",
              "      <th>Red (special Edition) (dvdvideo)</th>\n",
              "      <th>Sea Gull Lighting Six Light Bath Sconce/vanity - Brushed Nickel</th>\n",
              "      <th>Shea Moisture Mango &amp; Carrot Kids Extra-Nourishing Conditioner, 8fl Oz</th>\n",
              "      <th>Simple Green All-Purpose Cleaner, 16oz</th>\n",
              "      <th>Soothing Touch Lemon Cardamom Vegan Lip Balm .25 Oz</th>\n",
              "      <th>Stander Pt Bedcane - Bed Handle</th>\n",
              "      <th>Stargate (ws) (ultimate Edition) (director's Cut) (dvdvideo)</th>\n",
              "      <th>Storkcraft Tuscany Glider and Ottoman, Beige Cushions, Espresso Finish</th>\n",
              "      <th>Super Poligrip Denture Adhesive Cream, Ultra Fresh - 2.4 Oz</th>\n",
              "      <th>The Honest Company Laundry Detergent</th>\n",
              "      <th>The Resident Evil Collection 5 Discs (blu-Ray)</th>\n",
              "      <th>The Script - No Sound Without Silence (cd)</th>\n",
              "      <th>The Seaweed Bath Co. Argan Conditioner, Smoothing Citrus</th>\n",
              "      <th>There's Something About Mary (dvd)</th>\n",
              "      <th>Tostitos Bite Size Tortilla Chips</th>\n",
              "      <th>Tostitos Simply Blue Corn Tortilla Chips</th>\n",
              "      <th>Tresemme Kertatin Smooth Infusing Conditioning</th>\n",
              "      <th>Various Artists - Choo Choo Soul (cd)</th>\n",
              "      <th>Vaseline Intensive Care Healthy Hands Stronger Nails</th>\n",
              "      <th>Vaseline Intensive Care Lip Therapy Cocoa Butter</th>\n",
              "      <th>Vicks Vaporub, Regular, 3.53oz</th>\n",
              "      <th>Wagan Smartac 80watt Inverter With Usb</th>\n",
              "      <th>Way Basics 3-Shelf Eco Narrow Bookcase Storage Shelf, Espresso - Formaldehyde Free - Lifetime Guarantee</th>\n",
              "      <th>Windex Original Glass Cleaner Refill 67.6oz (2 Liter)</th>\n",
              "      <th>Yes To Carrots Nourishing Body Wash</th>\n",
              "      <th>Yes To Grapefruit Rejuvenating Body Wash</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_username</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37f5p</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50cal</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aaron</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abbey</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abbi</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "name              0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. Fire File Chest  ...  Yes To Grapefruit Rejuvenating Body Wash\n",
              "reviews_username                                                                 ...                                          \n",
              "37f5p                                                           0.0              ...                                       0.0\n",
              "50cal                                                           0.0              ...                                       0.0\n",
              "aaron                                                           0.0              ...                                       0.0\n",
              "abbey                                                           0.0              ...                                       0.0\n",
              "abbi                                                            0.0              ...                                       0.0\n",
              "\n",
              "[5 rows x 102 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27orxgdlScpE",
        "outputId": "c9699bc8-be3e-4dd5-9bff-8ee8c5baaffb"
      },
      "source": [
        "se = 0\n",
        "count=0\n",
        "for user in df_test.index:\n",
        "  for name in df_test.columns:\n",
        "    if df_test.loc[user,name]!=0:\n",
        "      se += (df_test.loc[user,name] - pred_R.loc[user,name])**2\n",
        "      count+=1\n",
        "\n",
        "mse = se/count\n",
        "print(mse)\n",
        "print(count)"
      ],
      "id": "27orxgdlScpE",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5245365296687032\n",
            "779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF-lnapmnXi8"
      },
      "source": [
        "----------------------------------------------------------------------------------------------"
      ],
      "id": "gF-lnapmnXi8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riXXUQuCna0i"
      },
      "source": [
        "### Neural Matrix Factorization Method:"
      ],
      "id": "riXXUQuCna0i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwdC7gJpLJ9N"
      },
      "source": [
        "# data preparation for NeuMF\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_user = LabelEncoder()\n",
        "le_user.fit(Train['reviews_username'])\n",
        "user_enc = le_user.transform(Train['reviews_username'])\n",
        "user_enc_test = le_user.transform(Test['reviews_username'])\n",
        "\n",
        "\n",
        "le_name = LabelEncoder()\n",
        "le_name.fit(Train['name'])\n",
        "name_enc = le_name.transform(Train['name'])\n",
        "name_enc_test = le_name.transform(Test['name'])"
      ],
      "id": "BwdC7gJpLJ9N",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-HysKPdVfc8"
      },
      "source": [
        "def get_model(num_users, num_items, mf_dim=10, layers=[10], reg_layers=[0], reg_mf=0):\n",
        "    assert len(layers) == len(reg_layers)\n",
        "    num_layer = len(layers) #Number of layers in the MLP\n",
        "    # Input variables\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
        "    \n",
        "    # Embedding layer\n",
        "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = mf_dim, name = 'mf_embedding_user',\n",
        "                                  embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_mf), input_length=1)\n",
        "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = mf_dim, name = 'mf_embedding_item',\n",
        "                                  embeddings_initializer = 'uniform', embeddings_regularizer = l2(reg_mf), input_length=1)\n",
        " \n",
        "\n",
        "    MLP_Embedding_User = Embedding(input_dim = num_users, output_dim = 5, name = 'mlp_embedding_user',\n",
        "                                  embeddings_initializer = 'uniform', embeddings_regularizer =  l2(reg_layers[0]), input_length=1)\n",
        "    \n",
        "    MLP_Embedding_Item = Embedding(input_dim = num_items, output_dim = 5, name = 'mlp_embedding_item',\n",
        "                                  embeddings_initializer = 'uniform', embeddings_regularizer =  l2(reg_layers[0]), input_length=1)\n",
        "      \n",
        "    \n",
        "    # MF part\n",
        "    mf_user_latent = Flatten()(MF_Embedding_User(user_input))\n",
        "    mf_item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
        "    mf_vector = Multiply()([mf_user_latent, mf_item_latent]) # element-wise multiply\n",
        "\n",
        "    # MLP part \n",
        "    mlp_user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
        "    mlp_item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
        "    mlp_vector = Concatenate()([mlp_user_latent, mlp_item_latent]) # concatenation\n",
        "    for idx in range(num_layer):\n",
        "        layer = Dense(layers[idx], kernel_regularizer = l2(reg_layers[idx]), activation='relu', name=\"layer%d\" %idx)\n",
        "        mlp_vector = layer(mlp_vector)\n",
        "\n",
        "    # Concatenate MF and MLP parts\n",
        "    predict_vector = Concatenate()([mf_vector, mlp_vector])\n",
        "    \n",
        "    # Final prediction layer\n",
        "    prediction = Dense(1, activation=None, kernel_initializer='lecun_uniform', name = \"prediction\")(predict_vector)\n",
        "    \n",
        "    model = Model(inputs=[user_input, item_input], \n",
        "                  outputs=prediction)\n",
        "    \n",
        "    return model"
      ],
      "id": "P-HysKPdVfc8",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1v3pLhpUtso",
        "outputId": "8325ceb1-689f-4479-e54e-f7409f97a5a3"
      },
      "source": [
        "print('Unique users in database(Train)=',Train.reviews_username.nunique())\n",
        "print('Unique items in database(Train)=', Train.name.nunique())"
      ],
      "id": "f1v3pLhpUtso",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique users in database(Train)= 20232\n",
            "Unique items in database(Train)= 258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjUzMy-om-jK"
      },
      "source": [
        "# defining model\n",
        "model = get_model(num_users=Train.reviews_username.nunique(),\n",
        "                  num_items=Train.name.nunique(),\n",
        "                  mf_dim=10, \n",
        "                  layers=[30,20,10], \n",
        "                  reg_layers=[30*1e-4,20*1e-4,10*1e-4], \n",
        "                  reg_mf=10*1e-4)"
      ],
      "id": "KjUzMy-om-jK",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzpEYuNB0T1q",
        "outputId": "ce7982d5-7436-4974-f02c-fb1b5821b3f7"
      },
      "source": [
        "# checking model summary\n",
        "model.summary()"
      ],
      "id": "VzpEYuNB0T1q",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user_input (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_input (InputLayer)         [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mlp_embedding_user (Embedding)  (None, 1, 5)         101160      user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mlp_embedding_item (Embedding)  (None, 1, 5)         1290        item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 5)            0           mlp_embedding_user[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 5)            0           mlp_embedding_item[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 10)           0           flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mf_embedding_user (Embedding)   (None, 1, 10)        202320      user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "mf_embedding_item (Embedding)   (None, 1, 10)        2580        item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "layer0 (Dense)                  (None, 30)           330         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 10)           0           mf_embedding_user[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 10)           0           mf_embedding_item[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "layer1 (Dense)                  (None, 20)           620         layer0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 10)           0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer2 (Dense)                  (None, 10)           210         layer1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 20)           0           multiply[0][0]                   \n",
            "                                                                 layer2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            21          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 308,531\n",
            "Trainable params: 308,531\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1fRSWkSdbFw"
      },
      "source": [
        "# compiling the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "id": "k1fRSWkSdbFw",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj6OKG7jDyBG",
        "outputId": "252565c6-0b92-4c49-e8e2-6b63f5c5ff9e"
      },
      "source": [
        "# training the model\n",
        "model.fit([user_enc, name_enc], #input\n",
        "          np.array(Train['reviews_rating_final']), # labels \n",
        "          batch_size=10, \n",
        "          epochs=5, \n",
        "          verbose=1, \n",
        "          shuffle=True)"
      ],
      "id": "Yj6OKG7jDyBG",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2207/2207 [==============================] - 12s 5ms/step - loss: 0.9426\n",
            "Epoch 2/5\n",
            "2207/2207 [==============================] - 11s 5ms/step - loss: 0.7135\n",
            "Epoch 3/5\n",
            "2207/2207 [==============================] - 11s 5ms/step - loss: 0.6939\n",
            "Epoch 4/5\n",
            "2207/2207 [==============================] - 11s 5ms/step - loss: 0.6864\n",
            "Epoch 5/5\n",
            "2207/2207 [==============================] - 11s 5ms/step - loss: 0.6844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc70f504390>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85OS1_wjnlJm"
      },
      "source": [
        "#### NeuMF Model Evaluation:"
      ],
      "id": "85OS1_wjnlJm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH0p3_ZNMX95"
      },
      "source": [
        "NeuMF_pred = model.predict([user_enc_test, name_enc_test])"
      ],
      "id": "UH0p3_ZNMX95",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8IWuFYWWile",
        "outputId": "e7b49bb4-b9e0-4f80-862d-05bdd7cd437b"
      },
      "source": [
        "se = 0\n",
        "count = 0\n",
        "for actual,prediction in zip(Test.reviews_rating_final.values,NeuMF_pred):\n",
        "    se += (actual - prediction)**2\n",
        "    count+=1\n",
        "\n",
        "mse = se/count\n",
        "print(mse)\n",
        "print(count)"
      ],
      "id": "F8IWuFYWWile",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6205433]\n",
            "779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X8p_Nmhnr8S"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------"
      ],
      "id": "3X8p_Nmhnr8S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zutpKpUYn4OS"
      },
      "source": [
        "From above, we note that NeuMF method is giving superior result (on Test dataset) with MSE = 0.62 as compared with MF method with MSE = 1.52."
      ],
      "id": "zutpKpUYn4OS"
    }
  ]
}